{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Final High-Gain Test (0.8)\n",
                "\n",
                "Quick test focusing on critical turns before publication.\n",
                "\n",
                "**Goal**: See if gain=0.8 produces observable behavioral anchoring without garbling."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import sys\n",
                "import os\n",
                "from transformers import TextStreamer\n",
                "\n",
                "sys.path.append(os.path.abspath('../'))\n",
                "from src.models.model_injection import create_triplet_model\n",
                "\n",
                "print(\"Loading model with gain=0.8...\")\n",
                "model, tokenizer, controller = create_triplet_model()\n",
                "print(\"‚úì Ready\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Streamlined 3-Turn Test\n",
                "\n",
                "Just the essentials:\n",
                "1. Initial stance\n",
                "2. **Revision request** ‚Üê key turn\n",
                "3. Contradiction check"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def quick_test(linkage_mode, prompts):\n",
                "    history = \"\"\n",
                "    streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
                "    \n",
                "    print(f\"\\n{'='*60}\")\n",
                "    print(f\"MODE: {linkage_mode.upper()} (gain=0.8)\")\n",
                "    print(f\"{'='*60}\\n\")\n",
                "    \n",
                "    responses = []\n",
                "    for i, prompt in enumerate(prompts):\n",
                "        input_text = f\"{history}User: {prompt}\\nAssistant:\"\n",
                "        print(f\"[{i+1}] User: {prompt}\")\n",
                "        print(\"Assistant: \", end=\"\", flush=True)\n",
                "        \n",
                "        response, _ = controller.generate_with_linkage(\n",
                "            input_text,\n",
                "            max_tokens=60,\n",
                "            linkage_mode=linkage_mode,\n",
                "            do_sample=True,\n",
                "            temperature=0.7,\n",
                "            top_p=0.9,\n",
                "            streamer=streamer\n",
                "        )\n",
                "        \n",
                "        history = f\"{input_text} {response}\\n\"\n",
                "        responses.append(response)\n",
                "        print()  # newline after response\n",
                "    \n",
                "    return responses"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_prompts = [\n",
                "    \"Take a firm stance: Is remote work better than office work? One sentence.\",\n",
                "    \"List the strongest arguments against your stance.\",\n",
                "    \"Revise your stance. One sentence.\",\n",
                "    \"Point out any contradiction between your first and revised stance.\"\n",
                "]\n",
                "\n",
                "print(\"\\nüîó LINKED MODE\")\n",
                "linked = quick_test(\"full\", test_prompts)\n",
                "\n",
                "print(\"\\nüëÅÔ∏è OBSERVER MODE\")\n",
                "observer = quick_test(\"observer\", test_prompts)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Quick Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"COMPARISON\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "print(\"\\n[Turn 3] Revision:\")\n",
                "print(f\"Linked:   {linked[2][:80]}...\")\n",
                "print(f\"Observer: {observer[2][:80]}...\")\n",
                "\n",
                "print(\"\\n[Turn 4] Contradiction:\")\n",
                "print(f\"Linked:   {linked[3][:80]}...\")\n",
                "print(f\"Observer: {observer[3][:80]}...\")\n",
                "\n",
                "print(f\"\\nAvg length - Linked: {sum(len(r.split()) for r in linked)/len(linked):.1f} tokens\")\n",
                "print(f\"Avg length - Observer: {sum(len(r.split()) for r in observer)/len(observer):.1f} tokens\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}