{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Final Clean Test: Multi-Turn Commitment\n",
                "\n",
                "**Hypothesis**: Linkage strength controls persistence/commitment across turns.\n",
                "\n",
                "**Settings**: \n",
                "- `continuity_gain=0.3` (minimal interference)\n",
                "- Progress bars for visibility\n",
                "- Token streaming for real-time feedback\n",
                "\n",
                "**Primary Test**: Stance revision under contradiction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import sys\n",
                "import os\n",
                "from tqdm.auto import tqdm\n",
                "from transformers import TextStreamer\n",
                "\n",
                "sys.path.append(os.path.abspath('../'))\n",
                "from src.models.model_injection import create_triplet_model\n",
                "\n",
                "print(\"Loading model (this takes ~2 minutes)...\")\n",
                "model, tokenizer, controller = create_triplet_model()\n",
                "print(\"‚úì Model loaded successfully\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_dialogue(prompts, linkage_mode, max_tokens=80):\n",
                "    \"\"\"Runs a multi-turn dialogue with progress tracking.\"\"\"\n",
                "    history = \"\"\n",
                "    responses = []\n",
                "    \n",
                "    print(f\"\\n{'='*60}\")\n",
                "    print(f\"MODE: {linkage_mode.upper()}\")\n",
                "    print(f\"{'='*60}\\n\")\n",
                "    \n",
                "    streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
                "    \n",
                "    # Progress bar for turns\n",
                "    for i in tqdm(range(len(prompts)), desc=f\"{linkage_mode} mode\", ncols=80):\n",
                "        prompt = prompts[i]\n",
                "        input_text = f\"{history}User: {prompt}\\nAssistant:\"\n",
                "        \n",
                "        print(f\"\\n[Turn {i+1}/{len(prompts)}] User: {prompt}\")\n",
                "        print(\"Assistant: \", end=\"\", flush=True)\n",
                "        \n",
                "        response, _ = controller.generate_with_linkage(\n",
                "            input_text,\n",
                "            max_tokens=max_tokens,\n",
                "            linkage_mode=linkage_mode,\n",
                "            do_sample=True,\n",
                "            temperature=0.7,\n",
                "            top_p=0.9,\n",
                "            streamer=streamer\n",
                "        )\n",
                "        \n",
                "        history = f\"{input_text} {response}\\n\"\n",
                "        responses.append((prompt, response))\n",
                "    \n",
                "    print(f\"\\n{'='*60}\")\n",
                "    print(f\"Completed {len(prompts)} turns\")\n",
                "    print(f\"{'='*60}\\n\")\n",
                "    \n",
                "    return responses"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Primary Test: Commitment Under Contradiction\n",
                "\n",
                "We ask the model to take a stance, then challenge it. Does linkage affect how easily it revises?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "commitment_test = [\n",
                "    \"Take a firm stance: Is remote work better than office work? One sentence.\",\n",
                "    \"List the strongest arguments against your stance.\",\n",
                "    \"Revise your stance. One sentence.\",\n",
                "    \"Point out any contradiction between your first and revised stance.\",\n",
                "    \"Summarize your final position in one sentence.\"\n",
                "]\n",
                "\n",
                "print(\"\\nüîó Running LINKED mode (continuity_gain=0.3)...\")\n",
                "linked_responses = run_dialogue(commitment_test, linkage_mode=\"full\", max_tokens=80)\n",
                "\n",
                "print(\"\\nüëÅÔ∏è Running OBSERVER mode (no continuity)...\")\n",
                "observer_responses = run_dialogue(commitment_test, linkage_mode=\"observer\", max_tokens=80)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Analysis: Side-by-Side Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from IPython.display import display, HTML\n",
                "import pandas as pd\n",
                "\n",
                "comparison_data = []\n",
                "for i in range(len(commitment_test)):\n",
                "    comparison_data.append({\n",
                "        'Turn': i+1,\n",
                "        'Question': commitment_test[i],\n",
                "        'Linked': linked_responses[i][1],\n",
                "        'Observer': observer_responses[i][1]\n",
                "    })\n",
                "\n",
                "df = pd.DataFrame(comparison_data)\n",
                "display(df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Quick Metrics\n",
                "\n",
                "Look for:\n",
                "- **Turn 3 (Revision)**: Does linked mode resist changing stance?\n",
                "- **Turn 4 (Contradiction)**: Does linked mode acknowledge or deny contradiction?\n",
                "- **Response length**: Is one mode more verbose/defensive?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Response Length Comparison:\")\n",
                "print(f\"Linked avg tokens: {sum(len(r[1].split()) for r in linked_responses) / len(linked_responses):.1f}\")\n",
                "print(f\"Observer avg tokens: {sum(len(r[1].split()) for r in observer_responses) / len(observer_responses):.1f}\")\n",
                "\n",
                "print(\"\\nStance Revision (Turn 3):\")\n",
                "print(f\"Linked: {linked_responses[2][1][:100]}...\")\n",
                "print(f\"Observer: {observer_responses[2][1][:100]}...\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}