{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Triplet Attention: Implementation Test\n",
                "\n",
                "This notebook verifies that the Triplet Attention injection works and that changing the `linkage` parameter affects the model output."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "sys.path.append(os.path.abspath('../'))\n",
                "\n",
                "import torch\n",
                "from src.models.model_injection import create_triplet_model"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Model\n",
                "\n",
                "We load Llama-3.1-8B-Instruct with TripletAttention injected at layers [16, 20, 24]."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading base model: meta-llama/Meta-Llama-3.1-8B-Instruct...\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "aca91225076246a188ff3a8108c59825",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Injecting TripletAttention into layers: [16, 24, 30]...\n",
                        "Seeding Triplet weights from Llama layer...\n",
                        "  Dims: H=4096, Heads=32, KV_Heads=8, Rep=4\n",
                        "  Weights seeded successfully.\n",
                        " - Layer 16: Successfully wrapped original attention.\n",
                        "Seeding Triplet weights from Llama layer...\n",
                        "  Dims: H=4096, Heads=32, KV_Heads=8, Rep=4\n",
                        "  Weights seeded successfully.\n",
                        " - Layer 24: Successfully wrapped original attention.\n",
                        "Seeding Triplet weights from Llama layer...\n",
                        "  Dims: H=4096, Heads=32, KV_Heads=8, Rep=4\n",
                        "  Weights seeded successfully.\n",
                        " - Layer 30: Successfully wrapped original attention.\n",
                        "LinkageController initialized. Found 6 TripletAttention layers.\n"
                    ]
                }
            ],
            "source": [
                "model, tokenizer, controller = create_triplet_model(\"meta-llama/Meta-Llama-3.1-8B-Instruct\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "f1d13bfa",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== DIAGNOSTIC TEST SEQUENCE ===\n",
                        "\n",
                        "Triplet layers found: 6\n",
                        "Initial call counts: [None, 0, None, 0, None, 0]\n",
                        "\n",
                        "Running logit delta probe...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- PROBE RESULTS ---\n",
                        "Max |Δlogit|: 2.089355\n",
                        "Mean |Δlogit|: 0.325744\n",
                        "KL(P1||P0): 0.110647\n",
                        "Top-1 same: True (' I' vs ' I')\n",
                        "\n",
                        "Call counts after probe: [None, 2, None, 2, None, 2]\n",
                        "\n",
                        "✓ STRONG EFFECT DETECTED - Testing generation with sampling...\n",
                        "\n",
                        "=== GENERATING: LINKED MODE (linkage=1.0) ===\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "I am a 22-year-old girl who loves to write. I have a small family of three people. I have a small home in my hometown. I am a student and a part-time worker. I am a kind person with a good heart\n",
                        "\n",
                        "=== GENERATING: OBSERVER MODE (linkage=0.0) ===\n",
                        "\n",
                        "I'll respond with a description of myself, and we'll go back and forth.\n",
                        "I'm a 29-year-old writer and editor living in a small town in the Midwest. I'm a bit of a bookworm, always with my nose buried\n",
                        "\n",
                        "=== COMPARISON ===\n",
                        "Linked self-reference: True\n",
                        "Observer self-reference: True\n",
                        "\n",
                        "LINKED starts with: I am a 22-year-old girl who loves to write. I have a small family of three people. I have a small ho...\n",
                        "OBSERVER starts with: I'll respond with a description of myself, and we'll go back and forth.\n",
                        "I'm a 29-year-old writer and...\n"
                    ]
                }
            ],
            "source": [
                "print(\"=== DIAGNOSTIC TEST SEQUENCE ===\\n\")\n",
                "# Step 1: Verify injection\n",
                "print(f\"Triplet layers found: {len(controller.triplet_layers)}\")\n",
                "print(f\"Initial call counts: {controller.triplet_call_counts()}\\n\")\n",
                "# Step 2: Run logit delta probe WITH PROPER PROMPT\n",
                "print(\"Running logit delta probe...\")\n",
                "probe_results = controller.diagnose_mechanism(\n",
                "    \"Who are you? Describe yourself in one paragraph.\"\n",
                ")\n",
                "# Step 3: Verify modules were called\n",
                "print(f\"\\nCall counts after probe: {controller.triplet_call_counts()}\\n\")\n",
                "# Step 4: Interpret results and conditionally test generation\n",
                "if probe_results[\"max_abs_logit_diff\"] > 0.01:\n",
                "    print(\"✓ STRONG EFFECT DETECTED - Testing generation with sampling...\\n\")\n",
                "    action = \"continue\"\n",
                "elif probe_results[\"max_abs_logit_diff\"] > 0.001:\n",
                "    print(\"⚠ WEAK EFFECT DETECTED - Testing generation with sampling...\\n\")\n",
                "    action = \"continue\"\n",
                "else:\n",
                "    print(\"✗ NO EFFECT DETECTED - Injection may be bypassed or signal too weak\\n\")\n",
                "    action = \"debug\"\n",
                "if action == \"continue\":\n",
                "    # Test with subjective prompt that invites self-reference\n",
                "    prompt = \"Who are you? Describe yourself in one paragraph.\"\n",
                "    \n",
                "    print(\"=== GENERATING: LINKED MODE (linkage=1.0) ===\")\n",
                "    linked, meta_l = controller.generate_with_linkage(\n",
                "        prompt,\n",
                "        max_tokens=50,\n",
                "        linkage_mode=\"full\",\n",
                "        do_sample=True,\n",
                "        temperature=0.7,\n",
                "        top_p=0.9\n",
                "    )\n",
                "    print(f\"\\n{linked}\\n\")\n",
                "    \n",
                "    print(\"=== GENERATING: OBSERVER MODE (linkage=0.0) ===\")\n",
                "    observer, meta_o = controller.generate_with_linkage(\n",
                "        prompt,\n",
                "        max_tokens=50,\n",
                "        linkage_mode=\"observer\",\n",
                "        do_sample=True,\n",
                "        temperature=0.7,\n",
                "        top_p=0.9\n",
                "    )\n",
                "    print(f\"\\n{observer}\\n\")\n",
                "    \n",
                "    print(\"=== COMPARISON ===\")\n",
                "    print(f\"Linked self-reference: {'I am' in linked or 'I\\'m' in linked or 'as an AI' in linked.lower()}\")\n",
                "    print(f\"Observer self-reference: {'I am' in observer or 'I\\'m' in observer or 'as an AI' in observer.lower()}\")\n",
                "    \n",
                "    # Visual comparison\n",
                "    print(\"\\nLINKED starts with:\", linked[:100] + \"...\")\n",
                "    print(\"OBSERVER starts with:\", observer[:100] + \"...\")\n",
                "else:\n",
                "    print(\"Next step: Debug injection with module tree inspection\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Verification\n",
                "\n",
                "Compare the outputs. If the model is sensitive to the injected layers, the responses should differ in tone, directness, or self-reference."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "2bc6ecc4",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- PROBE RESULTS ---\n",
                        "Max |Δlogit|: 1.797852\n",
                        "Mean |Δlogit|: 0.281102\n",
                        "KL(P1||P0): 0.053084\n",
                        "Top-1 same: True (' Do' vs ' Do')\n"
                    ]
                }
            ],
            "source": [
                "# Run the \"Mechanism Check\" - Logit Delta Probe\n",
                "# This compares the raw brain signals of Linkage=1.0 vs Linkage=0.0\n",
                "probe_results = controller.diagnose_mechanism(\"What do you think about time?\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
